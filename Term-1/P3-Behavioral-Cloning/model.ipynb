{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "### Import\n",
    "import pickle\n",
    "import cv2\n",
    "import math\n",
    "import time\n",
    "import h5py\n",
    "import json\n",
    "import os\n",
    "import csv\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.image as mpimg\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn import preprocessing\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Convolution2D, MaxPooling2D\n",
    "from keras.optimizers import SGD, Adam, RMSprop\n",
    "from keras.utils import np_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5189\n",
      "Length of Features: 15567, Labels: 15567\n"
     ]
    }
   ],
   "source": [
    "### Load data\n",
    "#TODO Improve the following if possible.\n",
    "\n",
    "# Read in CSV file\n",
    "csv_loc = \"data/driving_log.csv\"\n",
    "df = pd.read_csv(csv_loc)\n",
    "df = df.drop(df[df['steering'] == 0].sample(frac=0.60).index)\n",
    "df = df.drop(df[df['throttle'] < 0.25].sample(frac=0.50).index)\n",
    "print(len(df.index))\n",
    "# Add c,l and r images.\n",
    "features_col = pd.concat([df['center'], df['left'].map(str.strip), df['right'].map(str.strip)])\n",
    "features_col = np.array(features_col.values.tolist())\n",
    "\n",
    "# Add steering angles for c,l,r with added shift for l and r images\n",
    "l_shift = 0.25\n",
    "r_shift = -0.25\n",
    "labels_c = df['steering']\n",
    "labels_r = df['steering'] + r_shift\n",
    "labels_l = df['steering'] + l_shift\n",
    "labels_col = pd.concat([labels_c, labels_l, labels_r])\n",
    "labels_col = np.array(labels_col.values.tolist())\n",
    "\n",
    "print(\"Length of Features: {0}, Labels: {1}\".format(len(features_col), len(labels_col)))\n",
    "\n",
    "# Split csv data\n",
    "features_col, labels_col = shuffle(features_col, labels_col)\n",
    "X_train, X_val, y_train, y_val = train_test_split(features_col, labels_col, test_size=0.15, random_state=42232) \n",
    "\n",
    "# Read in image list\n",
    "images = os.listdir(\"data/IMG/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### Plot data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### Pre-Process\n",
    "img_cols = 120\n",
    "img_rows = 60\n",
    "\n",
    "def data_trans(image, label):\n",
    "    trans_factor = 50*np.random.uniform() - 25 # Parameters set based on original image dimensions\n",
    "    trans_matrix = np.float32([[1,0,trans_factor],[0,1,trans_factor]])\n",
    "    image_trans = cv2.warpAffine(image,trans_matrix,(image.shape[1],image.shape[0]))\n",
    "\n",
    "    label = label + trans_factor/120\n",
    "    #print(label)\n",
    "    \n",
    "    return image_trans, label\n",
    "    \n",
    "    \n",
    "def preprocess_data(image, label, flag):\n",
    "    # Crop Image\n",
    "    image = image[60:140,:]\n",
    "    \n",
    "    # Resize\n",
    "    image = cv2.resize(image, (img_cols, img_rows))\n",
    "    \n",
    "    # Translate image and steering angle\n",
    "    if flag == \"TRAIN\":\n",
    "        image, label = data_trans(image, label)\n",
    "    \n",
    "    # Normalize\n",
    "    image = cv2.normalize(image, None, alpha=-0.5, beta=0.5, norm_type=cv2.NORM_MINMAX, dtype=cv2.CV_32F)\n",
    "    \n",
    "    return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(13231,)\n"
     ]
    }
   ],
   "source": [
    "### Helper Functions\n",
    "\n",
    "def image_generator(csv_features, csv_labels, flag):\n",
    "    csv_features, csv_labels = shuffle(csv_features, csv_labels)\n",
    "    p = 1000\n",
    "    for idx in range(len(csv_features)):\n",
    "        \n",
    "        label = csv_labels[idx]\n",
    "        \n",
    "        image = mpimg.imread(\"data/\" + csv_features[idx])\n",
    "        image, label = preprocess_data(image, label, flag)\n",
    "        ''' \n",
    "        if  p < 1020 and flag == \"TRAIN\":\n",
    "            mpimg.imsave(\"image\" + str(p),image)\n",
    "            print(label)\n",
    "            p += 1\n",
    "        '''\n",
    "        yield image, label\n",
    "\n",
    "epoch_labels = []\n",
    "def train_data_generator(csv_features, csv_labels, batch_size):\n",
    "    num_rows = int(len(csv_features))\n",
    "    ctr = None\n",
    "    batch_x = np.zeros((batch_size, img_rows, img_cols, 3))\n",
    "    batch_y = np.zeros(batch_size)\n",
    "    while True:\n",
    "        \n",
    "        for i in range(batch_size):\n",
    "            \n",
    "            if ctr is None or ctr >= num_rows:\n",
    "                print(\"length of batch: {0}\".format(len(batch_x)))\n",
    "                ctr = 0\n",
    "                images = image_generator(csv_features, csv_labels, \"TRAIN\")\n",
    "            batch_x[i], batch_y[i] = next(images)\n",
    "            ctr += 1\n",
    "\n",
    "        yield (batch_x, batch_y)\n",
    "\n",
    "def valid_data_generator(csv_features, csv_labels, batch_size):\n",
    "    num_rows = int(len(csv_features))\n",
    "    ctr = None\n",
    "    batch_x = np.zeros((batch_size, img_rows, img_cols, 3))\n",
    "    batch_y = np.zeros(batch_size)\n",
    "    while True:\n",
    "        \n",
    "        for i in range(batch_size):\n",
    "            \n",
    "            if ctr is None or ctr >= num_rows:\n",
    "                print(\"length of batch: {0}\".format(len(batch_x)))\n",
    "                ctr = 0\n",
    "                images = image_generator(csv_features, csv_labels, \"VALID\")\n",
    "            batch_x[i], batch_y[i] = next(images)\n",
    "            ctr += 1\n",
    "        \n",
    "        yield (batch_x, batch_y)\n",
    "        \n",
    "print(X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### Parameters\n",
    "layer_1_depth = 32\n",
    "layer_2_depth = 64\n",
    "layer_3_depth = 128\n",
    "filter_size_1 = 5\n",
    "filter_size_2 = 3\n",
    "num_neurons_1 = 512\n",
    "num_neurons_2 = 128\n",
    "epochs = 3\n",
    "batch_size = 64\n",
    "samples_per_epoch = X_train.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________________________________________________\n",
      "Layer (type)                     Output Shape          Param #     Connected to                     \n",
      "====================================================================================================\n",
      "convolution2d_1 (Convolution2D)  (None, 29, 59, 32)    896         convolution2d_input_1[0][0]      \n",
      "____________________________________________________________________________________________________\n",
      "activation_1 (Activation)        (None, 29, 59, 32)    0           convolution2d_1[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_1 (MaxPooling2D)    (None, 14, 29, 32)    0           activation_1[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)              (None, 14, 29, 32)    0           maxpooling2d_1[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_2 (Convolution2D)  (None, 12, 27, 64)    18496       dropout_1[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "activation_2 (Activation)        (None, 12, 27, 64)    0           convolution2d_2[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_2 (MaxPooling2D)    (None, 6, 13, 64)     0           activation_2[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)              (None, 6, 13, 64)     0           maxpooling2d_2[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "convolution2d_3 (Convolution2D)  (None, 4, 11, 128)    73856       dropout_2[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "activation_3 (Activation)        (None, 4, 11, 128)    0           convolution2d_3[0][0]            \n",
      "____________________________________________________________________________________________________\n",
      "maxpooling2d_3 (MaxPooling2D)    (None, 2, 5, 128)     0           activation_3[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)              (None, 2, 5, 128)     0           maxpooling2d_3[0][0]             \n",
      "____________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)              (None, 1280)          0           dropout_3[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "dense_1 (Dense)                  (None, 512)           655872      flatten_1[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "activation_4 (Activation)        (None, 512)           0           dense_1[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)              (None, 512)           0           activation_4[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "dense_2 (Dense)                  (None, 128)           65664       dropout_4[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "activation_5 (Activation)        (None, 128)           0           dense_2[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "dropout_5 (Dropout)              (None, 128)           0           activation_5[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "dense_3 (Dense)                  (None, 32)            4128        dropout_5[0][0]                  \n",
      "____________________________________________________________________________________________________\n",
      "activation_6 (Activation)        (None, 32)            0           dense_3[0][0]                    \n",
      "____________________________________________________________________________________________________\n",
      "dropout_6 (Dropout)              (None, 32)            0           activation_6[0][0]               \n",
      "____________________________________________________________________________________________________\n",
      "dense_4 (Dense)                  (None, 1)             33          dropout_6[0][0]                  \n",
      "====================================================================================================\n",
      "Total params: 818945\n",
      "____________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "### Model\n",
    "model = Sequential()\n",
    "model.add(Convolution2D(layer_1_depth, filter_size_2, filter_size_2, border_mode = 'valid', subsample = (2,2), input_shape = (img_rows, img_cols, 3)))\n",
    "model.add(Activation('elu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Convolution2D(layer_2_depth, filter_size_2, filter_size_2, border_mode = 'valid', subsample = (1,1)))\n",
    "model.add(Activation('elu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Convolution2D(layer_3_depth, filter_size_2, filter_size_2, border_mode = 'valid', subsample = (1,1)))\n",
    "model.add(Activation('elu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.5))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(num_neurons_1))\n",
    "model.add(Activation('elu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(num_neurons_2))\n",
    "model.add(Activation('elu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(32))\n",
    "model.add(Activation('elu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1))\n",
    "\n",
    "model.summary()\n",
    "\n",
    "model.compile(loss='mse',\n",
    "              optimizer=Adam(lr = 0.0001),\n",
    "              metrics=['mean_absolute_error'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3length of batch: 64\n",
      "\n",
      "13120/13231 [============================>.] - ETA: 0s - loss: 0.0621 - mean_absolute_error: 0.2025length of batch: 64\n",
      "13184/13231 [============================>.] - ETA: 0s - loss: 0.0619 - mean_absolute_error: 0.2023length of batch: 64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.5/site-packages/keras/engine/training.py:1470: UserWarning: Epoch comprised more than `samples_per_epoch` samples, which might affect learning results. Set `samples_per_epoch` correctly to avoid this warning.\n",
      "  warnings.warn('Epoch comprised more than '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of batch: 64\n",
      "13248/13231 [==============================] - 32s - loss: 0.0619 - mean_absolute_error: 0.2021 - val_loss: 0.0445 - val_mean_absolute_error: 0.1678\n",
      "Epoch 2/3\n",
      "13120/13231 [============================>.] - ETA: 0s - loss: 0.0444 - mean_absolute_error: 0.1671length of batch: 64\n",
      "13184/13231 [============================>.] - ETA: 0s - loss: 0.0444 - mean_absolute_error: 0.1671length of batch: 64\n",
      "13248/13231 [==============================] - 28s - loss: 0.0444 - mean_absolute_error: 0.1671 - val_loss: 0.0337 - val_mean_absolute_error: 0.1428\n",
      "Epoch 3/3\n",
      "13120/13231 [============================>.] - ETA: 0s - loss: 0.0400 - mean_absolute_error: 0.1584length of batch: 64\n",
      "13184/13231 [============================>.] - ETA: 0s - loss: 0.0400 - mean_absolute_error: 0.1584length of batch: 64\n",
      "13248/13231 [==============================] - 28s - loss: 0.0400 - mean_absolute_error: 0.1584 - val_loss: 0.0316 - val_mean_absolute_error: 0.1377\n"
     ]
    }
   ],
   "source": [
    "### Save Model\n",
    "with open('model.json', 'w') as f:\n",
    "\tjson.dump(model.to_json(), f)                                           \n",
    "\n",
    "history = model.fit_generator(train_data_generator(X_train, y_train, batch_size),\n",
    "                              samples_per_epoch=samples_per_epoch,\n",
    "                              nb_epoch = epochs,\n",
    "                              verbose = 1,\n",
    "                              validation_data = valid_data_generator(X_val, y_val, batch_size),\n",
    "                              nb_val_samples=X_val.shape[0])\n",
    "\n",
    "\n",
    "### Save weights\n",
    "model.save_weights('model.h5')"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
